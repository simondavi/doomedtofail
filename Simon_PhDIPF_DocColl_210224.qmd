---
title: "The Role of Personal Entry Characteristics in Dropout from Teacher Education"
subtitle: "Doctoral Colloquium, 21 February 2024" 
title-block-banner: true
author: David Simon [david.simon@dipf.de]
date: today
date-format: "DD MMMM YYYY"
editor: source
execute:
  echo: true
  warning: false
  message: false
  cache: false
format: 
  html:
    theme: flatly
    fontsize: 1.0em
    toc: true
    toc-location: left
    toc-depth: 4
    embed-resources: true
    code-fold: show
    code-tools: true
    code-link: true
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: references.bib
---

## Introduction

Although political and social interest as well as research on dropout have increased, little is known about dropout from teacher education. We utilized a Latent-Class-Analysis to investigate dropout rates, as this allows us to map subgroups of students based on their individual characteristics prior to entering teacher education. We were interested in the question which combination of prerequisites makes it hard to study as successfully as their peers do. In addition we will investigate possible support mechanisms for a particular group of students who shows itself vulnerable to the conditions at higher education institutions.

We assume to find several statistically separable subgroups among which at least one could be theoretically described as a risk group equaling an accumulation of unfavorable prerequisites in regards to educational failure. Furthermore, we hypothesize that members of the risk group will not be able to integrate successfully into the social or academic domain when transitioning into higher education and that, as a result, they will not be able to make productive use of the learning opportunities available and therefore be more likely to drop out of teacher education.

This document is concerned with the first step of data analysis, the Latent-Class-Analysis. If you are interested in the whole proposal you can have a look at the preregistration here: <https://doi.org/10.17605/OSF.IO/D2K7Y>

I would like to ask you to read the following document. We had to make a number of decisions and I am interested in whether you find the approach convincing or not. The topics of interest are listed at the end of the document.


## Theoretical Background

Evidence from dropout research regularly highlights the relevance of individual characteristics prior to entering higher education, e.g. @isleib2019. In this vein several determinants that define the dropout process within a general population of students prior to entering a study program have been distinguished. These determinants encompass factors such as origin, personality and socialization in the education process [@heublein2014]. Disadvantages are to be expected in the case of lower socioeconomic status, migration background, non-Gymnasium entrance certificate, lower prior academic achievements, a completion of a vocational training prior to entering higher education, lower scores on the personality trait conscientiousness and a primarily extrinsic motivation for choosing a degree program. [@isleib2019].

The set of entry characteristics discussed in this strand of research will serve us as a set of indicators for a Latent-Class-Analysis:

1.  Socioeconomic background (parental education and parental occupation)

2.  Migration background (parents' place of birth)

3.  Type of entrance certificate (attended type of school)

4.  Prior academic achievement (grade point average)

5.  Big Five (extraversion, agreeableness, conscientiousness, neuroticism and openness)

6.  Motivation for choosing teacher education (intrinsic motivation and extrinsic motivation)


## Data Analysis

Analysis is based on data from the German Panel of Teacher Education as part of the Starting Cohort First-Year Students (SC5) of the National Educational Panel Study (NEPS) [@educatio2019].

```{r}
#| echo: false
library(haven)          # to import SPSS files
library(tidyverse)      # for data management
library(reshape)
library(reshape2)
library(rquery)         # to copy STATA merge behavior
library(rqdatatable)
library(fauxnaif)       # for defining missing values 
                          # (remotes::install_github("rossellhayes/fauxnaif")
library(psych)          # for scale construction
library(poLCA)          # for LCA
library(MASS)    
library(tidySEM)
library(scatterplot3d)
library(LCAplotter)     # library(devtools)
                          # devtools::install_github("DavidykZhao/LCA_plotter")
library(report)         # for producing reports 
library(lavaan)         # for SEM


#### ----------------- (1) Read Data and Data Management ----------------- ####

# Cohort Profile as a starting point

cohort <- haven::read_sav("Data_SC5_D_18-0-0/SC5_CohortProfile_D_18-0-0.sav") %>%
          dplyr::select(ID_t, wave, cohort,
                                    tx80121,      # oversample of tea edu (= 1)
                                    tx80107) %>%  # first participation in wave
          dplyr::filter(wave == 1)                       


# Filter measures from CATI:

cati_w1 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav") %>%
           dplyr::select(ID_t, wave, tg02001_ha,  # intended degree
                                     tg24150_g1,  # foreign student (!= 3)
                                     t731301_g1,  # parental education
                                     t731351_g1,  
                                     t731403_g8,  # parental occupation
                                     t731453_g8,
                                     t405060_g1,  # migration background
                                     t405090_g1,
                                     t70000m, t70000y, # date of birth
                                     t700001) %>% # gender
           dplyr::filter(wave == 1)
           
cati_b5 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav") %>%
           dplyr::select(ID_t, wave, t66800a, t66800f,           # extra
                                     t66800b, t66800g, t66800k,  # agree
                                     t66800c, t66800h,           # consc
                                     t66800d, t66800i,           # neuro
                                     t66800e, t66800j) %>%       # opene
          dplyr::filter(wave == 3)
  
cati_b5_w10 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav") %>%
               dplyr::select(ID_t, wave, t66800a, t66800f,           
                                         t66800b, t66800g, t66800k,  
                                         t66800c, t66800h,           
                                         t66800d, t66800i,           
                                         t66800e, t66800j) %>%      
               dplyr::filter(wave == 10)

cati_do1 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, tg60031) %>%
            dplyr::filter(wave == 10)


cati_doi <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, tg64051) %>%
            dplyr::filter(wave == 9)

  
# Filter measures from CAWI:

cati_do2 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, tg60021) %>%
            dplyr::filter(wave == 11)

cawi_w8 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav") %>%
           dplyr::select(ID_t, wave, tg61031, tg61032, tg61033,  # int mo
                                     tg61061, tg61062, tg61063,
                                     tg61041, tg61042, tg61043,  
                                     tg61021, tg61022, tg61023,  # ext mo
                                     tg61011, tg61012, tg61013,
                                     tg61071, tg61072, tg61073,  
                                     tg61051, tg61052, tg61053) %>%
           dplyr::filter(wave == 8)

cawi_sp1 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, tg53232, tg53234, tg53236,  # ac int
                                      tg53231, tg53233, tg53235,
                                      tg53211, tg53212, tg53213,
                                      tg53111, tg53112, tg53112,  # so int
                                      tg53121, tg53122, tg53123,
                                      t241011, t241012, t241013,  # for lo  
                                      t246411, t246412, t246413) %>%
                                      # practice orientation
            dplyr::filter(wave == 2)

cawi_sp2 <- haven::read_sav("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, t261843, t261845, t261846) %>%  # infor lo
            dplyr::filter(wave == 4)
                                      
                         
# Filter measures from spSchool:

spsch <- haven::read_sav("Data_SC5_D_18-0-0/SC5_spSchool_D_18-0-0.sav") %>%
         dplyr::select(ID_t, wave, spell, subspell, ts11204,       # school
                                                    ts11209,       # certificate
                                                    ts11218) %>%   # GPA
         dplyr::filter(subspell == 0)  %>%  # keep full / harmonized episodes
         dplyr::group_by(ID_t) %>% dplyr::slice_max(order_by = spell, 
                                                    with_ties = T) %>%
                                   dplyr::slice_tail(n = 1)  # keep highest spell 


# Filter measures from spVocTrain:

spvoc_pr <- haven::read_sav("Data_SC5_D_18-0-0/SC5_spVocTrain_D_18-0-0.sav") %>%
            dplyr::select(ID_t, wave, spell, subspell, tx20100,  # linkage
                                                       ts15201,  # type of voc
                                                       ts1512m,  # end year voc
                                                       ts1512y,  # end month voc
                                                       ts15218) %>%  # finished 
           dplyr::filter(subspell == 0 & tx20100 == 1 
                         & ts15201 <= 4 
                         & ts1512y <= 2010 & ts1512m <= 10) %>%  
           # keep full / harmonized episodes & completion before WT 2010
           dplyr::group_by(ID_t) %>%
           dplyr::summarise(ts15218 = case_when(any(ts15218 == 1) ~ 3,
                                                any(ts15218 == 2) 
                                                & any(is.na(ts15218)) ~ as.numeric(NA), 
                                                all(ts15218 == 2) ~ 4))
           # summarize the data per person across spells
           # 3 = yes, 4 = no


spvoc <- haven::read_sav("Data_SC5_D_18-0-0/SC5_spVocTrain_D_18-0-0.sav") %>%   # (?) später nochmal Filter mit h_aktstu
         dplyr::select(ID_t, wave, spell, subspell, 
                       h_aktstu,        # 1st study episode WT 2010
                       tg24202_g1,      # type of intended teaching degree
                       tg24170_g5,      # subject group
                       tg01003_ha) %>%  # Type of higher education inst         # Im Vergleich zu oben nicht nur harmonized data, weil dann nicht immer wave 1
         dplyr::filter(wave == 1) %>%
         dplyr::filter(h_aktstu == 1) %>%
         dplyr::group_by(ID_t) %>% dplyr::slice_max(order_by = spell,
                                                    with_ties = T) %>%
         dplyr::slice_tail(n = 1)  


####  -------------------------- (2) Merge Data -------------------------- ####

data <- rquery::natural_join(cohort, cati_w1,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_b5,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_b5_w10,  # supply Big 5
                             by = "ID_t",        # with answers from wave 10
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_w8,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_sp1,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_sp2,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_do1,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_doi,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_do2,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spsch,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spvoc_pr,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spvoc,
                             by = "ID_t",
                             jointype = "LEFT") %>%
  
                             # dplyr::filter(tx80121 == 1) %>%
                             # oversample of tea edu
                             dplyr::filter(tg02001_ha <= 7) %>%
                             # intended degree = teacher education (wave 1)
                             dplyr::filter(tg24150_g1 != 3) %>%
                             # exclude foreign students
                             dplyr::filter(h_aktstu == 1) %>%                    
                             # only start of studies WT 2010
                             dplyr::filter(tx80107 == 1) %>%
                             # only first participation in wave 1
                             dplyr::select(-wave) %>%
                             # drop wave, contains no information anymore
                             
                             dplyr::mutate(across(everything(), 
                                                  ~ fauxnaif::na_if_in(., ~ . < 0)))
                             # replace all negative Values with NA  

####  ------------ (3) Compute Scale Scores and New Variables ------------ ####

## entry characteristics
                             
# SES: Parental education (par_edu), parental occupation (par_ocu)
data2 <- data %>%
  dplyr::mutate(par_edu = case_when((t731301_g1 < 9 & t731351_g1 < 9) ~ 1,
                                    (t731301_g1 >= 9 & t731351_g1 >= 9) ~ 3,
                                    (t731301_g1 >= 9 | t731351_g1 >= 9) ~ 2,
                                    TRUE ~ as.numeric(NA))) %>%
                                    # 1 = no parent tertiary education, 2 = one 
                                    # parent, 3 = both parents
  
  dplyr::mutate(par_ocu = case_when((t731403_g8 >= 9 & t731453_g8 >= 9) |       
                                    (t731403_g8 == 4 & t731453_g8 == 4) ~ 1,
                                    # (t731403_g8 %in% c(1:3, 5:8) | 
                                    # t731453_g8 %in% c(1:3, 5:8)) ~ 2,
                                    (t731403_g8 <= 2 | t731453_g8 <= 2) ~ 3,
                                    (t731403_g8 %in% c(3, 5:8) | 
                                     t731453_g8 %in% c(3, 5:8)) ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = working class,
                                    # 2 = intermediate class
                                    # 3 = upper class

# migration background
data3 <- data2 %>% 
  dplyr::mutate(mig_bac = case_when((t405060_g1 <= 2 & t405090_g1 <= 2) ~ 1,
                                    (t405060_g1 == 3 | t405090_g1 == 3) ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = both parents born in Germany, 
                                    # 2 = at least one abroad

data4 <- data3 %>% 
  dplyr::mutate(typ_sch = case_when(ts11204 != 8 ~ 1,
                                    ts11204 == 8 ~ 2,
                                    TRUE ~ as.numeric(NA)))  %>%
                                    # 1 = non-Gymnasium,
                                    # 2 = Gymnasium (also Kolleg)
  
  dplyr::mutate(paa_gpa = case_when(ts11218 >= 3.6 & ts11218 <= 4.0 ~ 1,
                                    ts11218 >= 2.6 & ts11218 < 3.6 ~ 2,
                                    ts11218 >= 1.6 & ts11218 < 2.6 ~ 3,
                                    ts11218 >= 1.0 & ts11218 < 1.6 ~ 4,
                                    TRUE ~ as.numeric(NA)))  %>%
                                    # 1 = sufficient, 2 = satisfactory, 
                                    # 3 = good, 4 = very good)
  
  dplyr::mutate(voc_tra = case_when(ts15218 == 4 ~ 1,
                                    ts15218 == 3 ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = no, 2 = yes

# individual characteristics 
# (big 5, motivation for choosing teacher education (femola))

# scales
data5 <- data4 %>% 
  dplyr::mutate(big_ext = rowMeans(subset(data4, select = c(t66800a, t66800f)),
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_agr = rowMeans(subset(data4, select = c(t66800b, t66800g, 
                                                            t66800k)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_con = rowMeans(subset(data4, select = c(t66800c, t66800h)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_neu = rowMeans(subset(data4, select = c(t66800d, t66800i)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_ope = rowMeans(subset(data4, select = c(t66800e, t66800j)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_edi = rowMeans(subset(data4, select = c(tg61031, tg61032, 
                                                            tg61033)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_ssi = rowMeans(subset(data4, select = c(tg61061, tg61062, 
                                                            tg61063)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_abe = rowMeans(subset(data4, select = c(tg61041, tg61042, 
                                                            tg61043)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_tff = rowMeans(subset(data4, select = c(tg61021, tg61022, 
                                                            tg61023)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_fis = rowMeans(subset(data4, select = c(tg61011, tg61012, 
                                                            tg61013)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_lod = rowMeans(subset(data4, select = c(tg61071, tg61072, 
                                                            tg61073)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_soi = rowMeans(subset(data4, select = c(tg61051, tg61052, 
                                                            tg61053)),
                                   na.rm = TRUE)) %>%
  
  dplyr::mutate(fem_inm = rowMeans(subset(data4, select = c(tg61031, tg61032, 
                                                            tg61033, tg61061, 
                                                            tg61062, tg61063,
                                                            tg61041, tg61042, 
                                                            tg61043)),
                                   na.rm = TRUE)) %>%
                                  
  dplyr::mutate(fem_exm = rowMeans(subset(data4, select = c(tg61021, tg61022, 
                                                            tg61023, tg61011, 
                                                            tg61012, tg61013,
                                                            tg61071, tg61072, 
                                                            tg61073, tg61051, 
                                                            tg61052, tg61053)),
                                   na.rm = TRUE))
```

The resulting sample comprises **5775 Persons** (*M* = 20.73, *SD* = 2.87, 4337 women) who were first enrolled in Teacher Education in WT 2010.

### Step 1: Examination of the Observed Data

While describing the data numerically, see Table below, we noticed that the hypothetically continuous variables (Big 5 and Motivation for choosing teacher education) do not have a lot unique values and very right-skewed and some response categories have near-zero frequencies. It is recommended that continuous variables should have many unique values; if not, it may be better to model them as ordinal [@vanlissa2023].

```{r}
#| echo: false
data6 <- data5 %>% 
  dplyr::mutate(across(everything(), ~ ifelse(is.nan(.x), NA, .x)))

# examine variables
df <- data6 %>%
  dplyr::select(par_edu, 
                par_ocu, 
                mig_bac, 
                typ_sch, 
                paa_gpa,
                big_ext, 
                big_agr, 
                big_con, 
                big_neu,
                big_ope, 
                fem_inm, 
                fem_exm)

desc <- tidySEM::descriptives(df)
desc <- desc[, c("name", "type", "n", "missing", "unique", "mode")]
desc

desc_plot <- data6 %>%
   dplyr::mutate(
    across(c(big_ext, 
             big_agr, 
             big_con, 
             big_neu,
             big_ope, 
             fem_inm, 
             fem_exm),
           as.factor)) %>%
  
  dplyr::select(big_ext, 
                big_agr, 
                big_con, 
                big_neu,
                big_ope, 
                fem_inm, 
                fem_exm)

names(desc_plot) <- paste0("Value.", names(desc_plot))
desc_plot <- reshape(desc_plot, varying = names(desc_plot), direction = "long")

desc_plot <- ggplot(desc_plot, aes(x = Value)) + geom_bar() + 
             facet_wrap(~ time, scales = "free") + theme_bw()                              

desc_plot
```

Consequently we decided to rearange these variables into categories. In order to retain the distributions of each variable we computed a three-level variable for the Big 5 Variables, including the categories low, medium and high. As a cut-off we used each variables tertile. In case of the Motivation for choosing teacher education and the circumstance of skewness we took each variables median, dichotomizing the indicator into two categories: low and high.

```{r}
#| echo: false
data7 <- data6 %>% 
  dplyr::mutate(ext_rnk = case_when(big_ext < 3.0 ~ 1,
                                     between(big_ext, 3.0, 3.5) ~ 2,
                                     big_ext > 3.5 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(agr_rnk = case_when(big_agr < 3.333333 ~ 1,
                                     between(big_agr, 3.333333, 3.666667) ~ 2,
                                     big_agr > 3.666667 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(con_rnk = case_when(big_con < 3.0 ~ 1,                       
                                     between(big_con, 3.0, 3.5) ~ 2,
                                     big_con > 3.5 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(neu_rnk = case_when(big_neu < 2.5 ~ 1,
                                     between(big_neu, 2.5, 3.0) ~ 2,
                                     big_neu > 3.0 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(ope_rnk = case_when(big_ope < 3.0 ~ 1,
                                    between(big_ope, 3.0, 3.5) ~ 2,
                                    big_ope > 3.5 ~ 3,
                                    TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(inm_di = ifelse(fem_inm < 3.22, 1, 2),                      
                exm_di = ifelse(fem_exm <= 2.25, 1, 2))
                

dat_lca <- data7 %>% 
  dplyr::mutate(
    across(c(par_edu,
             par_ocu,
             mig_bac,
             typ_sch,
             paa_gpa,
             ext_rnk,
             agr_rnk,
             con_rnk,
             neu_rnk,
             ope_rnk,
             inm_di,
             exm_di),
           as.factor))


# plot the data
dat_plot <- dat_lca %>% 
  dplyr::select(par_edu,
                par_ocu,
                mig_bac,
                typ_sch,
                paa_gpa,
                ext_rnk,
                agr_rnk,
                con_rnk,
                neu_rnk,
                ope_rnk,
                inm_di,
                exm_di)

desc2 <- tidySEM::descriptives(dat_plot)
desc2 <- desc2[, c("name", "type", "n", "missing", "unique")]
desc2

names(dat_plot) <- paste0("Value.", names(dat_plot))
dat_plot <- reshape(dat_plot, varying = names(dat_plot), direction = "long")

dat_plot <- ggplot(dat_plot, aes(x = Value)) + geom_bar() + 
  facet_wrap(~ time, scales = "free") + theme_bw()                              

dat_plot
```

The variables shown above form the input variables for the calculation.

### Step 2: Data Processing 

```{r}
#| echo: false
f <- with(dat_lca, cbind(par_edu, par_ocu, mig_bac, typ_sch, paa_gpa,
                         ext_rnk, agr_rnk, con_rnk, neu_rnk,
                         ope_rnk, inm_di, exm_di) ~ 1)
  
set.seed(123)
lc1 <- poLCA(f, dat_lca, nclass = 1, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc2 <- poLCA(f, dat_lca, nclass = 2, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc3 <- poLCA(f, dat_lca, nclass = 3, na.rm = FALSE, nrep = 10, maxiter = 8000)  
lc4 <- poLCA(f, dat_lca, nclass = 4, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc5 <- poLCA(f, dat_lca, nclass = 5, na.rm = FALSE, nrep = 10, maxiter = 8000)
lc6 <- poLCA(f, dat_lca, nclass = 6, na.rm = FALSE, nrep = 10, maxiter = 5000)

# generate dataframe with fit-values
results <- data.frame(Modell = c("Modell 1"),
                      log_likelihood = lc1$llik,
                      df = lc1$resid.df,
                      BIC = lc1$bic,
                      ABIC = (-2 * lc1$llik) + ((log((lc1$N + 2) / 24)) * lc1$npar),
                      CAIC = (-2 * lc1$llik) + lc1$npar * (1 + log(lc1$N)), 
                      likelihood_ratio = lc1$Gsq)

results$Modell <- as.integer(results$Modell)
results[1,1] <- c("Modell 1")
results[2,1] <- c("Modell 2")
results[3,1] <- c("Modell 3")
results[4,1] <- c("Modell 4")
results[5,1] <- c("Modell 5")
results[6,1] <- c("Modell 6")

results[2,2] <- lc2$llik
results[3,2] <- lc3$llik
results[4,2] <- lc4$llik
results[5,2] <- lc5$llik
results[6,2] <- lc6$llik

results[2,3] <- lc2$resid.df
results[3,3] <- lc3$resid.df
results[4,3] <- lc4$resid.df
results[5,3] <- lc5$resid.df
results[6,3] <- lc6$resid.df

results[2,4] <- lc2$bic
results[3,4] <- lc3$bic
results[4,4] <- lc4$bic
results[5,4] <- lc5$bic
results[6,4] <- lc6$bic

results[2,5] <- (-2*lc2$llik) + ((log((lc2$N + 2)/24)) * lc2$npar) #abic
results[3,5] <- (-2*lc3$llik) + ((log((lc3$N + 2)/24)) * lc3$npar)
results[4,5] <- (-2*lc4$llik) + ((log((lc4$N + 2)/24)) * lc4$npar)
results[5,5] <- (-2*lc5$llik) + ((log((lc5$N + 2)/24)) * lc5$npar)
results[6,5] <- (-2*lc6$llik) + ((log((lc6$N + 2)/24)) * lc6$npar)
 
results[2,6] <- (-2*lc2$llik) + lc2$npar * (1 + log(lc2$N)) #caic
results[3,6] <- (-2*lc3$llik) + lc3$npar * (1 + log(lc3$N))
results[4,6] <- (-2*lc4$llik) + lc4$npar * (1 + log(lc4$N))
results[5,6] <- (-2*lc5$llik) + lc5$npar * (1 + log(lc5$N))
results[6,6] <- (-2*lc6$llik) + lc6$npar * (1 + log(lc6$N))
 
results[2,7] <- lc2$Gsq
results[3,7] <- lc3$Gsq
results[4,7] <- lc4$Gsq
results[5,7] <- lc5$Gsq
results[6,7] <- lc6$Gsq

# add entropy
entropy <- function (p) sum(-p*log(p))

results$R2_entropy
results[1,8] <- c("-")

error_prior <- entropy(lc2$P) # class proportions model 2
error_post <- mean(apply(lc2$posterior,1, entropy),na.rm = TRUE)
results[2,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc3$P) # class proportions model 3
error_post <- mean(apply(lc3$posterior,1, entropy),na.rm = TRUE)
results[3,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc4$P) # class proportions model 4
error_post <- mean(apply(lc4$posterior,1, entropy),na.rm = TRUE)
results[4,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc5$P) # class proportions model 5
error_post <- mean(apply(lc5$posterior,1, entropy),na.rm = TRUE)
results[5,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc6$P) # class proportions model 6
error_post <- mean(apply(lc6$posterior,1, entropy),na.rm = TRUE)
results[6,8] <- round(((error_prior-error_post) / error_prior), 3)

colnames(results) <- c("Model","log-likelihood","resid. df","BIC","aBIC","cAIC",
                       "likelihood-ratio","Entropy")

lca_results <- results
```

```{r}
#| echo: false
results
```

We compute the Latentl-Class-Analysis following the guide by [@weller2020]. Model fit was examined based on our theoretical understanding of dropout from teacher education and the BIC (Bayesian Information Criterion) as a statistical criterium, with lower BIC indicating better model fit [@nylund2007]. We will stop adding classes, if the BIC increases three subsequent class solutions.

Additionally, we reviewed classification diagnostics criteria. We desired entropy above .8 and the lowest average latent class posterior probability to be between .80 and .90 [@weller2020].

We decided that the three class solutions is to be preferred. It is the model with the lowest BIC and the highest Entropy. Even if this and the lowest average latent class posterior probability are not as high as we desired, we interpret them as acceptable.

The average latent posterior probabilities are presented in a matrix with diagonals representing the average probability of a person being assigned to a class given the indicator variables used. Higher diagonal values are desirable. Off-diagonal elements in the posterior probability matrix contain probabilities of cases that belong in one class being assigned to another class [@bauer2021]. The average latent class posterior probabilities of the three class solution are:

```{r}
#| echo: false
meanpostprob <- round(aggregate(x = lc3$posterior,
                                by = list(lc3$predclass),FUN = "mean") , 2)
meanpostprob
```


### Final Class Solution

```{r}
#| echo: false
best_model <- lc3
plot <-  profile_plot(data = dat_lca, num_var = 12, model = lc3, form = f) 
plot
```

One group of the above can be classified a risk group. It compromised 18 % of the sample. Members of this group are characterized through a high probability of being a first-generation student whose parents can be assigned to working class. Students of this group had the highest probability of having a migration background and more likely attained their higher education entrance certificate not at a Gymnasium (type of school leading to upper secondary education and the entrance qualification for universities) and with a lower grade point average. Regarding there personality traits, they were more likely highly extroverted, open and, contrary to what was assumed showed the highest probability of being high in conscientiousness among all groups. Regarding their motivations of choosing teacher education, members of this group described themselves most likely as high extrinsically motivated and low intrinsically motivated. Overall, the first profile showed potentially unfavorable values regarding several indicators and might be interpreted as a group of students potentially at-risk for educational failure. 


## Further Considerations

We will then assign each case to a specific class (group) based on their posterior class membership probabilities and use this as a manifest variable for further analyses. As this procedure is not uncontroversial and under suspicion of producing biased results [@bauer2021] we followed @sinha2020 and use da probability cut-off of ≥ 0.5 to assign class.

```{r}
#| echo: false
data6 <- data6 %>%
  dplyr::mutate(class = case_when(lc3$posterior[,1]  >= 0.5 &
                                    lc3$posterior[,2] < 0.5 &
                                    lc3$posterior[,3] < 0.5 ~ 1,
                                  lc3$posterior[,2]  >= 0.5 &
                                    lc3$posterior[,1] < 0.5 &
                                    lc3$posterior[,3] < 0.5 ~ 2,
                                  lc3$posterior[,3]  >= 0.5 &
                                    lc3$posterior[,1] < 0.5 &
                                    lc3$posterior[,2] < 0.5 ~ 3,
                                  TRUE ~ as.numeric(NA)))
```

## Questions

-   Handling of variables (Dichotomization of Big 5, ...)
-   Model selection
-   Graphical presentation of the final model
-   Individual class assignment by modal posterior probabilty
