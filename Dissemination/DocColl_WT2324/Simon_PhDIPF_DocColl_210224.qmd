---
title: "The Role of Personal Entry Characteristics in Dropout from Teacher Education"
subtitle: "Doctoral Colloquium, 21 February 2024" 
title-block-banner: true
author: David Simon
date: today
date-format: "DD MMMM YYYY"
editor: source
execute:
  echo: false
  warning: false
  message: false
  cache: true
format: 
  html:
    echo: true
    theme: flatly
    fontsize: 1.1em
    toc: true
    toc-location: left
    toc-depth: 3
    embed-resources: true
    code-fold: true
    code-tools: true
    code-link: true
  pdf:
    echo: false
    toc: true
    toc-depth: 2
    fontsize: 10pt
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: references.bib
---

## Brief Introduction and Research Questions

Despite growing interest in dropout research, limited attention has been given to the context of teacher education. We utilized a Latent-Class-Analysis to investigate dropout, as this allows us to map subgroups of students based on their individual characteristics prior to entering teacher education. In doing so we are able to take multiple characteristics and their interactions into account at the same time.

Evidence from general dropout research regularly highlights the relevance of individual characteristics prior to entering higher education, such as socioeconomic, familiar and educational background, personality or motivation for choosing a study subject. We are interested in the question which combination of prerequisites makes people disadvantaged by the conditions at higher education institutions. Our assumption is, that some groups of students do not succeed in integrating into the social or academic domain of higher education institutions and that, as a result, they will not be able to make productive use of the learning opportunities available and therefore be more likely to drop out of teacher education.

This concept is derived from the Student Integration Model [@tinto1975], one of the more influential theories aiming to explain dropout. It distinguishes between the social and academic integration of students and assumes that those who are not sufficiently integrated into the corresponding social and academic domain within higher education institutions decide to drop out. Academic integration encompasses academic performance as proof of formal affiliation as well as an adjustment to the norms held by higher education institutions themselves (e.g. achievement orientation). Social integration refers to the establishment of contacts with faculty and students, providing support and cognitive stimulation. Both types of integration are seen to foster goal and institutional commitment, which we think will be reflected in an increased engagement and an increased utilization of learning opportunities available.

Consequently, we aim to answer three research questions:

*Research Question 1:* How many statistically distinct subgroups, regarding the entry characteristics of first-year teacher students, are there and can at least one of them be theoretically described as a risk group equaling an accumulation of unfavorable prerequisites in regards to educational failure?

*Research Question 2:* Do members of this group (these groups) show higher dropout rates compared to their peers?

*Research Question 3:* Can this relationship between risk group(s) and dropout from teacher education be explained through a failure of integration into the social or academic domain of higher education institutions and the subsequent unproductive utilization of learning opportunities?

This document is concerned with the first step of data analysis, the Latent-Class-Analysis, in order to address Research Question 1. If you are interested in the whole proposal you can have a look at the preregistration here: <https://doi.org/10.17605/OSF.IO/D2K7Y>.

I would like to ask you to read the following document. We had to make a number of decisions and I am interested in whether you find the approach convincing or not. The topics of interest are listed at the end of the document (section Questions).

## Data Analysis

### Variable Selection

Several determinants that define the dropout process within a general population of students prior to entering a study program have been distinguished [@heublein2014]. Disadvantages are to be expected in the case of lower socioeconomic status, migration background, non-Gymnasium entrance certificate, lower prior academic achievements, a completion of a vocational training prior to entering higher education, lower scores on the personality trait conscientiousness and a primarily extrinsic motivation for choosing a degree program [@isleib2019]. The set of entry characteristics discussed in this strand of research served us as a set of indicators for the Latent-Class-Analysis:

+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Variable name                                                                             |                                                                                          |
+===========================================================================================+==========================================================================================+
| Parental education                                                                        | 1 = no parent has attained tertiary education (first generation students)\               |
|                                                                                           | 2 = one parent has attained tertiary education\                                          |
|                                                                                           | 3 = both parents have attained tertiary education                                        |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Parental occupation                                                                       | 1 = working class\                                                                       |
|                                                                                           | 2 = intermediate class\                                                                  |
|                                                                                           | 3 = upper class\                                                                         |
|                                                                                           | *(EGP class scheme, the higher level of occupational class among both parents was used)* |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Migration background                                                                      | 1 = no, if both parents were born in Germany\                                            |
|                                                                                           | 2 = yes, if at least one parent was born abroad                                          |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Type of entrance certificate                                                              | 1 = non-Gymnasium\                                                                       |
|                                                                                           | 2 = Gymnasium                                                                            |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Prior academic achievement (grade point average)                                          | 1 = 3.0--4.0 ("sufficient")\                                                             |
|                                                                                           | 2 = 2.6--3.5 ("satisfactory")\                                                           |
|                                                                                           | 3 = 1.6--2.5 ("good")\                                                                   |
|                                                                                           | 4 = 1.0--1.5 ("very good")                                                               |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Big Five (extraversion, agreeableness, conscientiousness, neuroticism and openness)       | 10-item short version of the Big Five Inventory [@RAMMSTEDT2007203], Response scale:\    |
|                                                                                           | 1 = does not apply at all\                                                               |
|                                                                                           | 2 = does rather not apply\                                                               |
|                                                                                           | 3 = does partly apply\                                                                   |
|                                                                                           | 4 = does rather apply\                                                                   |
|                                                                                           | 5 = does completely apply                                                                |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+
| Motivation for choosing teacher education (intrinsic motivation and extrinsic motivation) | Motivation for choosing teacher education questionnaire[@femola], Response scale:\       |
|                                                                                           | 1 = not apply at that time at all\                                                       |
|                                                                                           | 2 = rather not apply at that time\                                                       |
|                                                                                           | 3 = did rather apply at that time\                                                       |
|                                                                                           | 4 = did completely apply at the time                                                     |
+-------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+

### Data Base

Our analyses are based on data from the German Panel of Teacher Education as part of the Starting Cohort First-Year Students (SC5) of the National Educational Panel Study (NEPS) [@educatio2019].The NEPS initially included about 18000 first-year students in the winter term 2010/2011 and an oversampling of teacher education students (about 5500 students). From 2014 onwards, multiple survey instruments, for example, aspects of professional competence, instructional practices or professional development, were specifically addressed to teachers. The data was collected in 19 waves until 2022 [@NEPS] .

```{r}
library(haven)          # to import SPSS files
library(tidyverse)      # for data management
library(reshape)
library(reshape2)
library(rquery)         # to copy STATA merge behavior
library(rqdatatable)
library(fauxnaif)       # for defining missing values 
                          # (remotes::install_github("rossellhayes/fauxnaif")
library(psych)          # for scale construction
library(poLCA)          # for LCA
library(MASS)    
library(tidySEM)
library(scatterplot3d)
library(LCAplotter)     # library(devtools)
                          # devtools::install_github("DavidykZhao/LCA_plotter")
library(report)         # for producing reports 
library(lavaan)         # for SEM
library(ggpubr)         # for arranging plots
library(here)           # to find my files


#### ----------------- (1) Read Data and Data Management ----------------- ####

# Cohort Profile as a starting point

cohort <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_CohortProfile_D_18-0-0.sav")) %>%
          dplyr::select(ID_t, wave, cohort,
                                    tx80121,      # oversample of tea edu (= 1)
                                    tx80107) %>%  # first participation in wave
          dplyr::filter(wave == 1)                       


# Filter measures from CATI:

cati_w1 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav")) %>%
           dplyr::select(ID_t, wave, tg02001_ha,  # intended degree
                                     tg24150_g1,  # foreign student (!= 3)
                                     t731301_g1,  # parental education
                                     t731351_g1,  
                                     t731403_g8,  # parental occupation
                                     t731453_g8,
                                     t405060_g1,  # migration background
                                     t405090_g1,
                                     t70000m, t70000y, # date of birth
                                     t700001) %>% # gender
           dplyr::filter(wave == 1)
           
cati_b5 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav")) %>%
           dplyr::select(ID_t, wave, t66800a, t66800f,           # extra
                                     t66800b, t66800g, t66800k,  # agree
                                     t66800c, t66800h,           # consc
                                     t66800d, t66800i,           # neuro
                                     t66800e, t66800j) %>%       # opene
          dplyr::filter(wave == 3)
  
cati_b5_w10 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav")) %>%
               dplyr::select(ID_t, wave, t66800a, t66800f,           
                                         t66800b, t66800g, t66800k,  
                                         t66800c, t66800h,           
                                         t66800d, t66800i,           
                                         t66800e, t66800j) %>%      
               dplyr::filter(wave == 10)

cati_do1 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, tg60031) %>%
            dplyr::filter(wave == 10)


cati_doi <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCATI_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, tg64051) %>%
            dplyr::filter(wave == 9)

  
# Filter measures from CAWI:

cati_do2 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, tg60021) %>%
            dplyr::filter(wave == 11)

cawi_w8 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav")) %>%
           dplyr::select(ID_t, wave, tg61031, tg61032, tg61033,  # int mo
                                     tg61061, tg61062, tg61063,
                                     tg61041, tg61042, tg61043,  
                                     tg61021, tg61022, tg61023,  # ext mo
                                     tg61011, tg61012, tg61013,
                                     tg61071, tg61072, tg61073,  
                                     tg61051, tg61052, tg61053) %>%
           dplyr::filter(wave == 8)

cawi_sp1 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, tg53232, tg53234, tg53236,  # ac int
                                      tg53231, tg53233, tg53235,
                                      tg53211, tg53212, tg53213,
                                      tg53111, tg53112, tg53112,  # so int
                                      tg53121, tg53122, tg53123,
                                      t241011, t241012, t241013,  # for lo  
                                      t246411, t246412, t246413) %>%
                                      # practice orientation
            dplyr::filter(wave == 2)

cawi_sp2 <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_pTargetCAWI_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, t261843, t261845, t261846) %>%  # infor lo
            dplyr::filter(wave == 4)
                                      
                         
# Filter measures from spSchool:

spsch <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_spSchool_D_18-0-0.sav")) %>%
         dplyr::select(ID_t, wave, spell, subspell, ts11204,       # school
                                                    ts11209,       # certificate
                                                    ts11218) %>%   # GPA
         dplyr::filter(subspell == 0)  %>%  # keep full / harmonized episodes
         dplyr::group_by(ID_t) %>% dplyr::slice_max(order_by = spell, 
                                                    with_ties = T) %>%
                                   dplyr::slice_tail(n = 1)  # keep highest spell 


# Filter measures from spVocTrain:

spvoc_pr <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_spVocTrain_D_18-0-0.sav")) %>%
            dplyr::select(ID_t, wave, spell, subspell, tx20100,  # linkage
                                                       ts15201,  # type of voc
                                                       ts1512m,  # end year voc
                                                       ts1512y,  # end month voc
                                                       ts15218) %>%  # finished 
           dplyr::filter(subspell == 0 & tx20100 == 1 
                         & ts15201 <= 4 
                         & ts1512y <= 2010 & ts1512m <= 10) %>%  
           # keep full / harmonized episodes & completion before WT 2010
           dplyr::group_by(ID_t) %>%
           dplyr::summarise(ts15218 = case_when(any(ts15218 == 1) ~ 3,
                                                any(ts15218 == 2) 
                                                & any(is.na(ts15218)) ~ as.numeric(NA), 
                                                all(ts15218 == 2) ~ 4))
           # summarize the data per person across spells
           # 3 = yes, 4 = no


spvoc <- haven::read_sav(here("Data_SC5_D_18-0-0/SC5_spVocTrain_D_18-0-0.sav")) %>%   
         dplyr::select(ID_t, wave, spell, subspell, 
                       h_aktstu,        # 1st study episode WT 2010
                       tg24202_g1,      # type of intended teaching degree
                       tg24170_g5,      # subject group
                       tg01003_ha) %>%  # Type of higher education inst          
         dplyr::filter(wave == 1) %>%
         dplyr::filter(h_aktstu == 1) %>%
         dplyr::group_by(ID_t) %>% dplyr::slice_max(order_by = spell,
                                                    with_ties = T) %>%
         dplyr::slice_tail(n = 1)  


####  -------------------------- (2) Merge Data -------------------------- ####

data <- rquery::natural_join(cohort, cati_w1,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_b5,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_b5_w10,  # supply Big 5
                             by = "ID_t",        # with answers from wave 10
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_w8,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_sp1,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, cawi_sp2,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_do1,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_doi,
                             by = "ID_t",
                             jointype = "LEFT")

data <- rquery::natural_join(data, cati_do2,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spsch,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spvoc_pr,
                             by = "ID_t",
                             jointype = "LEFT") 

data <- rquery::natural_join(data, spvoc,
                             by = "ID_t",
                             jointype = "LEFT") %>%
  
                             # dplyr::filter(tx80121 == 1) %>%
                             # oversample of tea edu
                             dplyr::filter(tg02001_ha <= 7) %>%
                             # intended degree = teacher education (wave 1)
                             dplyr::filter(tg24150_g1 != 3) %>%
                             # exclude foreign students
                             dplyr::filter(h_aktstu == 1) %>%                    
                             # only start of studies WT 2010
                             dplyr::filter(tx80107 == 1) %>%
                             # only first participation in wave 1
                             dplyr::select(-wave) %>%
                             # drop wave, contains no information anymore
                             
                             dplyr::mutate(across(everything(), 
                                                  ~ fauxnaif::na_if_in(., ~ . < 0)))
                             # replace all negative Values with NA  

####  ------------ (3) Compute Scale Scores and New Variables ------------ ####

## entry characteristics
                             
# SES: Parental education (par_edu), parental occupation (par_ocu)
data2 <- data %>%
  dplyr::mutate(par_edu = case_when((t731301_g1 < 9 & t731351_g1 < 9) ~ 1,
                                    (t731301_g1 >= 9 & t731351_g1 >= 9) ~ 3,
                                    (t731301_g1 >= 9 | t731351_g1 >= 9) ~ 2,
                                    TRUE ~ as.numeric(NA))) %>%
                                    # 1 = no parent tertiary education, 2 = one 
                                    # parent, 3 = both parents
  
  dplyr::mutate(par_ocu = case_when((t731403_g8 >= 9 & t731453_g8 >= 9) |       
                                    (t731403_g8 == 4 & t731453_g8 == 4) ~ 1,
                                    # (t731403_g8 %in% c(1:3, 5:8) | 
                                    # t731453_g8 %in% c(1:3, 5:8)) ~ 2,
                                    (t731403_g8 <= 2 | t731453_g8 <= 2) ~ 3,
                                    (t731403_g8 %in% c(3, 5:8) | 
                                     t731453_g8 %in% c(3, 5:8)) ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = working class,
                                    # 2 = intermediate class
                                    # 3 = upper class

# migration background
data3 <- data2 %>% 
  dplyr::mutate(mig_bac = case_when((t405060_g1 <= 2 & t405090_g1 <= 2) ~ 1,
                                    (t405060_g1 == 3 | t405090_g1 == 3) ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = both parents born in Germany, 
                                    # 2 = at least one abroad

data4 <- data3 %>% 
  dplyr::mutate(typ_sch = case_when(ts11204 != 8 ~ 1,
                                    ts11204 == 8 ~ 2,
                                    TRUE ~ as.numeric(NA)))  %>%
                                    # 1 = non-Gymnasium,
                                    # 2 = Gymnasium (also Kolleg)
  
  dplyr::mutate(paa_gpa = case_when(ts11218 >= 3.6 & ts11218 <= 4.0 ~ 1,
                                    ts11218 >= 2.6 & ts11218 < 3.6 ~ 2,
                                    ts11218 >= 1.6 & ts11218 < 2.6 ~ 3,
                                    ts11218 >= 1.0 & ts11218 < 1.6 ~ 4,
                                    TRUE ~ as.numeric(NA)))  %>%
                                    # 1 = sufficient, 2 = satisfactory, 
                                    # 3 = good, 4 = very good)
  
  dplyr::mutate(voc_tra = case_when(ts15218 == 4 ~ 1,
                                    ts15218 == 3 ~ 2,
                                    TRUE ~ as.numeric(NA)))
                                    # 1 = no, 2 = yes

# individual characteristics 
# (big 5, motivation for choosing teacher education (femola))

# scales
data5 <- data4 %>% 
  dplyr::mutate(big_ext = rowMeans(subset(data4, select = c(t66800a, t66800f)),
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_agr = rowMeans(subset(data4, select = c(t66800b, t66800g, 
                                                            t66800k)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_con = rowMeans(subset(data4, select = c(t66800c, t66800h)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_neu = rowMeans(subset(data4, select = c(t66800d, t66800i)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(big_ope = rowMeans(subset(data4, select = c(t66800e, t66800j)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_edi = rowMeans(subset(data4, select = c(tg61031, tg61032, 
                                                            tg61033)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_ssi = rowMeans(subset(data4, select = c(tg61061, tg61062, 
                                                            tg61063)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_abe = rowMeans(subset(data4, select = c(tg61041, tg61042, 
                                                            tg61043)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_tff = rowMeans(subset(data4, select = c(tg61021, tg61022, 
                                                            tg61023)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_fis = rowMeans(subset(data4, select = c(tg61011, tg61012, 
                                                            tg61013)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_lod = rowMeans(subset(data4, select = c(tg61071, tg61072, 
                                                            tg61073)), 
                                   na.rm = TRUE))  %>%
  dplyr::mutate(fem_soi = rowMeans(subset(data4, select = c(tg61051, tg61052, 
                                                            tg61053)),
                                   na.rm = TRUE)) %>%
  
  dplyr::mutate(fem_inm = rowMeans(subset(data4, select = c(tg61031, tg61032, 
                                                            tg61033, tg61061, 
                                                            tg61062, tg61063,
                                                            tg61041, tg61042, 
                                                            tg61043)),
                                   na.rm = TRUE)) %>%
                                  
  dplyr::mutate(fem_exm = rowMeans(subset(data4, select = c(tg61021, tg61022, 
                                                            tg61023, tg61011, 
                                                            tg61012, tg61013,
                                                            tg61071, tg61072, 
                                                            tg61073, tg61051, 
                                                            tg61052, tg61053)),
                                   na.rm = TRUE))
```

The resulting sample comprises **5775 first-year teacher students** (*M* = 20.73 years, *SD* = 2.87 years, 4337 women).

### Examination of the Observed Data

While describing the data numerically, see table below, it is noticeable that the hypothetically continuous variables (Big 5 and motivation for choosing teacher education) do have just a few unique values and some response categories have near-zero frequencies. It is recommended that continuous variables should have "many" unique values and, if not, it is advised to better model them as ordinal [@vanlissa2023].

```{r}
data6 <- data5 %>% 
  dplyr::mutate(across(everything(), ~ ifelse(is.nan(.x), NA, .x)))

round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
  df[,nums] <- round(df[,nums], digits = digits)
  (df)
}

# examine variables
df <- data6 %>%
  dplyr::select(par_edu, 
                par_ocu, 
                mig_bac, 
                typ_sch, 
                paa_gpa,
                big_ext, 
                big_agr, 
                big_con, 
                big_neu,
                big_ope, 
                fem_inm, 
                fem_exm) %>%
  dplyr::rename(parental_education = par_edu) %>%
  dplyr::rename(parental_occupation = par_ocu) %>%
  dplyr::rename(migration_background = mig_bac) %>%
  dplyr::rename(type_of_school = typ_sch) %>%
  dplyr::rename(prior_academic_achievement = paa_gpa) %>%
  dplyr::rename(extraversion = big_ext) %>%
  dplyr::rename(agreeableness = big_agr) %>%
  dplyr::rename(conscientiousness = big_con) %>%
  dplyr::rename(neuroticism = big_neu) %>%
  dplyr::rename(openness = big_ope) %>%
  dplyr::rename(intrinsic_motivation = fem_inm) %>%
  dplyr::rename(extrinsic_motivation = fem_exm)

desc <- tidySEM::descriptives(df)
desc <- desc[, c("name", "type", "n", "missing", "unique", "mode")]
desc <- round_df(desc, digits = 2)
desc

desc_plot <- data6 %>%
  dplyr::select(big_ext,
                big_agr,
                big_con, 
                big_neu,
                big_ope,
                fem_inm, 
                fem_exm) %>%
  dplyr::rename(extraversion = big_ext) %>%
  dplyr::rename(agreeableness = big_agr) %>%
  dplyr::rename(conscientiousness = big_con) %>%
  dplyr::rename(neuroticism = big_neu) %>%
  dplyr::rename(openness = big_ope) %>%
  dplyr::rename(intrinsic_motivation = fem_inm) %>%
  dplyr::rename(extrinsic_motivation = fem_exm)

a <- ggplot(desc_plot, aes(extraversion)) + geom_bar() + theme_bw()
b <- ggplot(desc_plot, aes(agreeableness)) + geom_bar() + theme_bw() 
c <- ggplot(desc_plot, aes(conscientiousness)) + geom_bar() + theme_bw()
d <- ggplot(desc_plot, aes(neuroticism)) + geom_bar() + theme_bw() 
e <- ggplot(desc_plot, aes(openness)) + geom_bar() + theme_bw()
f <- ggplot(desc_plot, aes(intrinsic_motivation)) + geom_bar() + theme_bw()
g <- ggplot(desc_plot, aes(extrinsic_motivation)) + geom_bar() + theme_bw()

desc_plot<- ggarrange(a, b, c, d, e, f, g, 
                      ncol = 3, nrow = 3)

desc_plot
```

Consequently, we decided to rearrange these variables into categories. In order to retain the distributions of each variable we computed a three-level variable for the Big 5, including the categories low, medium and high. As a cut-off we used each variables tertile as there was a strong central tendency. In case of the motivation for choosing teacher education we took each variables median, dichotomizing the indicator into two categories: low and high. The procedure assumed that the presence of a risk factor is of interest in the present study, e.g. high levels of neuroticism. The aim was to be able to map such characteristics using this categorization.

```{r}
data7 <- data6 %>% 
  dplyr::mutate(ext_rnk = case_when(big_ext < 3.0 ~ 1,
                                     between(big_ext, 3.0, 3.5) ~ 2,
                                     big_ext > 3.5 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(agr_rnk = case_when(big_agr < 3.333333 ~ 1,
                                     between(big_agr, 3.333333, 3.666667) ~ 2,
                                     big_agr > 3.666667 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(con_rnk = case_when(big_con < 3.0 ~ 1,                       
                                     between(big_con, 3.0, 3.5) ~ 2,
                                     big_con > 3.5 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(neu_rnk = case_when(big_neu < 2.5 ~ 1,
                                     between(big_neu, 2.5, 3.0) ~ 2,
                                     big_neu > 3.0 ~ 3,
                                     TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(ope_rnk = case_when(big_ope < 3.0 ~ 1,
                                    between(big_ope, 3.0, 3.5) ~ 2,
                                    big_ope > 3.5 ~ 3,
                                    TRUE ~ as.numeric(NA))) %>%
  dplyr::mutate(inm_di = ifelse(fem_inm < 3.22, 1, 2),                      
                exm_di = ifelse(fem_exm <= 2.25, 1, 2))
                

dat_lca <- data7 %>% 
  dplyr::mutate(
    across(c(par_edu,
             par_ocu,
             mig_bac,
             typ_sch,
             paa_gpa,
             ext_rnk,
             agr_rnk,
             con_rnk,
             neu_rnk,
             ope_rnk,
             inm_di,
             exm_di),
           as.factor))

# plot the data
dat_plot <- dat_lca %>% 
  dplyr::select(par_edu,
                par_ocu,
                mig_bac,
                typ_sch,
                paa_gpa,
                ext_rnk,
                agr_rnk,
                con_rnk,
                neu_rnk,
                ope_rnk,
                inm_di,
                exm_di) %>%
  dplyr::rename(parental_education = par_edu) %>%
  dplyr::rename(parental_occupation = par_ocu) %>%
  dplyr::rename(migration_background = mig_bac) %>%
  dplyr::rename(type_of_school = typ_sch) %>%
  dplyr::rename(prior_academic_achievement = paa_gpa) %>%
  dplyr::rename(extraversion = ext_rnk) %>%
  dplyr::rename(agreeableness = agr_rnk) %>%
  dplyr::rename(conscientiousness = con_rnk) %>%
  dplyr::rename(neuroticism = neu_rnk) %>%
  dplyr::rename(openness = ope_rnk) %>%
  dplyr::rename(intrinsic_motivation = inm_di) %>%
  dplyr::rename(extrinsic_motivation = exm_di)

a <- ggplot(data = subset(dat_plot, !is.na(extraversion)), aes(extraversion)) + geom_bar() + theme_bw()
b <- ggplot(data = subset(dat_plot, !is.na(agreeableness)), aes(agreeableness)) + geom_bar() + theme_bw()
c <- ggplot(data = subset(dat_plot, !is.na(conscientiousness)), aes(conscientiousness)) + geom_bar() + theme_bw()
d <- ggplot(data = subset(dat_plot, !is.na(neuroticism)), aes(neuroticism)) + geom_bar() + theme_bw() 
e <- ggplot(data = subset(dat_plot, !is.na(openness)), aes(openness)) + geom_bar() + theme_bw()
f <- ggplot(data = subset(dat_plot, !is.na(intrinsic_motivation)), aes(intrinsic_motivation)) + geom_bar() + theme_bw()
g <- ggplot(data = subset(dat_plot, !is.na(extrinsic_motivation)), aes(extrinsic_motivation)) + geom_bar() + theme_bw()


desc2 <- tidySEM::descriptives(dat_plot)
desc2 <- desc2[, c("name", "type", "n", "missing", "unique")]
desc2 <- round_df(desc2, digits = 2)
desc2

dat_plot <- ggarrange(a, b, c, d, e, f, g, 
                      ncol = 3, nrow = 3)
dat_plot
```

The variables shown above formed the input variables for further analyses.

### Data Processing

We computed the Latent-Class-Analysis following the guide by [@weller2020] using the software poLCA [@JSSv042i10]. The package handles missing data by excluding any manifest variables with missing observations from the calculation. The priors within the expectation-maximization algorithm are updated in using as many or as few manifest variables as are observed for each individual [@JSSv042i10]. This follows the assumption that in computing LCA specific handling of missing values is not necessary.

```{r}
#| output: false
f <- with(dat_lca, cbind(par_edu, par_ocu, mig_bac, typ_sch, paa_gpa,
                         ext_rnk, agr_rnk, con_rnk, neu_rnk,
                         ope_rnk, inm_di, exm_di) ~ 1)
  
set.seed(123)
lc1 <- poLCA(f, dat_lca, nclass = 1, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc2 <- poLCA(f, dat_lca, nclass = 2, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc3 <- poLCA(f, dat_lca, nclass = 3, na.rm = FALSE, nrep = 10, maxiter = 8000)  
lc4 <- poLCA(f, dat_lca, nclass = 4, na.rm = FALSE, nrep = 10, maxiter = 5000)
lc5 <- poLCA(f, dat_lca, nclass = 5, na.rm = FALSE, nrep = 10, maxiter = 8000)
lc6 <- poLCA(f, dat_lca, nclass = 6, na.rm = FALSE, nrep = 10, maxiter = 5000)

# generate dataframe with fit-values
results <- data.frame(Modell = c("Modell 1"),
                      log_likelihood = lc1$llik,
                      df = lc1$resid.df,
                      BIC = lc1$bic,
                      ABIC = (-2 * lc1$llik) + ((log((lc1$N + 2) / 24)) * lc1$npar),
                      CAIC = (-2 * lc1$llik) + lc1$npar * (1 + log(lc1$N)), 
                      likelihood_ratio = lc1$Gsq)

results$Modell <- as.integer(results$Modell)
results[1,1] <- c("Modell 1")
results[2,1] <- c("Modell 2")
results[3,1] <- c("Modell 3")
results[4,1] <- c("Modell 4")
results[5,1] <- c("Modell 5")
results[6,1] <- c("Modell 6")

results[2,2] <- lc2$llik
results[3,2] <- lc3$llik
results[4,2] <- lc4$llik
results[5,2] <- lc5$llik
results[6,2] <- lc6$llik

results[2,3] <- lc2$resid.df
results[3,3] <- lc3$resid.df
results[4,3] <- lc4$resid.df
results[5,3] <- lc5$resid.df
results[6,3] <- lc6$resid.df

results[2,4] <- lc2$bic
results[3,4] <- lc3$bic
results[4,4] <- lc4$bic
results[5,4] <- lc5$bic
results[6,4] <- lc6$bic

results[2,5] <- (-2*lc2$llik) + ((log((lc2$N + 2)/24)) * lc2$npar) #abic
results[3,5] <- (-2*lc3$llik) + ((log((lc3$N + 2)/24)) * lc3$npar)
results[4,5] <- (-2*lc4$llik) + ((log((lc4$N + 2)/24)) * lc4$npar)
results[5,5] <- (-2*lc5$llik) + ((log((lc5$N + 2)/24)) * lc5$npar)
results[6,5] <- (-2*lc6$llik) + ((log((lc6$N + 2)/24)) * lc6$npar)
 
results[2,6] <- (-2*lc2$llik) + lc2$npar * (1 + log(lc2$N)) #caic
results[3,6] <- (-2*lc3$llik) + lc3$npar * (1 + log(lc3$N))
results[4,6] <- (-2*lc4$llik) + lc4$npar * (1 + log(lc4$N))
results[5,6] <- (-2*lc5$llik) + lc5$npar * (1 + log(lc5$N))
results[6,6] <- (-2*lc6$llik) + lc6$npar * (1 + log(lc6$N))
 
results[2,7] <- lc2$Gsq
results[3,7] <- lc3$Gsq
results[4,7] <- lc4$Gsq
results[5,7] <- lc5$Gsq
results[6,7] <- lc6$Gsq

# add entropy
entropy <- function (p) sum(-p*log(p))

results$R2_entropy
results[1,8] <- c("-")

error_prior <- entropy(lc2$P) # class proportions model 2
error_post <- mean(apply(lc2$posterior,1, entropy),na.rm = TRUE)
results[2,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc3$P) # class proportions model 3
error_post <- mean(apply(lc3$posterior,1, entropy),na.rm = TRUE)
results[3,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc4$P) # class proportions model 4
error_post <- mean(apply(lc4$posterior,1, entropy),na.rm = TRUE)
results[4,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc5$P) # class proportions model 5
error_post <- mean(apply(lc5$posterior,1, entropy),na.rm = TRUE)
results[5,8] <- round(((error_prior-error_post) / error_prior), 3)

error_prior <- entropy(lc6$P) # class proportions model 6
error_post <- mean(apply(lc6$posterior,1, entropy),na.rm = TRUE)
results[6,8] <- round(((error_prior-error_post) / error_prior), 3)

colnames(results) <- c("Model","log-likelihood","resid.df","BIC","aBIC","cAIC",
                       "likelihood-ratio", "Entropy")

results <- round_df(results, digits = 2)
```

+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| model    | log-likelihood | resid. df | BIC   | aBIC  | cAIC  | likelihood-ratio | entropy |
+:========:+:==============:+:=========:+:=====:+:=====:+:=====:+:================:+:=======:+
| Modell 1 | -41519         | 5754      | 83221 | 83154 | 83242 | 6636             |         |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| Modell 2 | -41059         | 5732      | 82490 | 82353 | 82533 | 6264             | 0.48    |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| Modell 3 | -40950         | 5710      | 82464 | 82257 | 82257 | 6212             | 0.64    |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| Modell 4 | -40879         | 5688      | 82512 | 82235 | 82599 | 6165             | 0.43    |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| Modell 5 | -40839         | 5666      | 82622 | 82276 | 82731 | 6145             | 0.38    |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+
| Modell 6 | -40800         | 5644      | 82735 | 82735 | 82866 | 6111             | 0.51    |
+----------+----------------+-----------+-------+-------+-------+------------------+---------+

: **Results of the Latent -Class-Analysis (Model Fit Parameters)**

*Note.* resd.df = residual degrees of freedom, BIC = Bayesian Information Criterion, aBIC = adjusted BIC, cAIC = consistent Akaike Information Criterion.

Model fit was examined based on our theoretical understanding of dropout from teacher education and the BIC (Bayesian Information Criterion) as a statistical criterion, with lower BIC indicating better model fit [@nylund2007].

Additionally, we reviewed the following classification diagnostics criteria. We desired entropy above .80 and the lowest average latent class posterior probability to be between .80 and .90 [@weller2020].

We decided that the three-class solutions is to be preferred. It is the model with the lowest BIC and the highest entropy. Even if the latter and the lowest average latent class posterior probabilities are not as high as we desired, we interpret them as acceptable.

The average latent posterior probabilities are presented in a matrix with diagonals. It represents the average probability of a person being assigned to a class given the indicator variables used. Higher diagonal values are desirable. Off-diagonal elements in the posterior probability matrix contain probabilities of cases that belong in one class being assigned to another class [@bauer2021]. The average latent class posterior probabilities of the three-class solution are displayed below:

```{r}
meanpostprob <- round(aggregate(x = lc3$posterior,
                                by = list(lc3$predclass),FUN = "mean") , 2)
meanpostprob
```

### Final Class Solution

```{r}
best_model <- lc3
plot <-  profile_plot(data = dat_lca, num_var = 12, model = lc3, form = f) 
print(plot +
        ggtitle("class 1 = 19 %, class 2 = 36 %, class 3 = 45 %"))
```

*Figure 1.* Latent Classes. par_edu = parental education (1, 2, 3), par_ocu = parental occupation (1, 2, 3), mig_bac = migration background (1, 2), typ_sch = type of school (1, 2), paa_gpa = prior academic achievment (1, 2, 3, 4), ext_rnk = extraversion (1, 2, 3), agr_rnk = agreeableness (1, 2, 3), con_rnk = conscientiousness (1, 2, 3), neu_rnk = neuroticism (1, 2, 3), ope_rnk = openness (1, 2, 3), inm_di = intrinsic motivation for choosing teacher education (1, 2), exm_di = extrinsic motivation (1, 2). Possible manifestations are displayed in brackets.

The classes can be described as follows:

**Class 1** compromised 19 % of the sample.

Regarding social and familiar background variables this group of students is characterized through a high probability of being a first-generation student whose parents can be more likely assigned to working class. Students of this group had the highest probability of having a migration background and more likely attained their higher education entrance certificate not at a Gymnasium and with a low grade point average (most likely sufficient).

Regarding their personality traits, they were more likely highly extraverted, open and, contrary to what was assumed, showed the highest probability of being high in conscientiousness among all groups.

Regarding their motivation of choosing teacher education, members of this group described themselves most likely as high extrinsically motivated and low intrinsically motivated.

**Class 2** describes 36 % of the sample.

In contrast to class 1, members of class 2 are descried through the highest probability of both parents have attained tertiary education and are working under upper class regulations of employment. They most likely have no migration background, attained a Gymnasium and finished school with most likely good grades.

Describing their personality it can be said that they most likely fall in the medium categories of extraversion, agreeableness, conscientiousness, neuroticism and openness.

They describe their motivation for choosing teacher education more likely to be intrinsically motivated and are ambiguous regarding extrinsic motives showing roughly equal conditional probabilities for both categories.

The **third** class compromised 45 % of the sample.

Regarding social and familiar background variables this group of students is, comparable to class 1, characterized through a marginalization due to a high probability of having a migration background and being a first-generation student. There parents most likely can be assigned to intermediate class. But, in contrast to members of class 1, these students more likely attained their higher education entrance certificate at a Gymnasium and with a "good" grade point average - more comparable to class 2.

Also, regarding there personality traits, members showed similar distribution patterns as members of class 2 did.

Regarding their motivation of choosing teacher education, members of this group described themselves most likely as high intrinsically motivated and low extrinsically motivated.

**Overall**, class 2 shows conditional response probabilities regarding socioeconomic, familiar and educational background, personality and motivation that overall indicate positive effects in regards to academic success.

While class 3 seems to be at-risk in terms of their socioeconomic and familiar background they tend to have advantageous educational prerequisites as well as a favorable motivational state.

Class 1 showed itself potentially unfavorable on most variables and might be interpreted as a group of students potentially at-risk for educational failure and dropout. It must be noted that their high probability of being high in conscientiousness is contradicting.

Statistical tests on which conditional response probabilities differ from each other have not yet been computed. The portrayal is purely descriptive.

## Further Considerations

In order to compute results on the other predictions, we would like to assign each case to a specific group based on their posterior class membership probabilities in order to use this as a manifest variable for further analyses. As this procedure is not uncontroversial and under suspicion of producing biased results [@bauer2021] we followed @sinha2020 and used a probability cut-off of ≥ 0.5 to assign class in order to address uncertainty.

```{r}
data6 <- data6 %>%
  dplyr::mutate(class = case_when(lc3$posterior[,1]  >= 0.5 &
                                    lc3$posterior[,2] < 0.5 &
                                    lc3$posterior[,3] < 0.5 ~ 1,
                                  lc3$posterior[,2]  >= 0.5 &
                                    lc3$posterior[,1] < 0.5 &
                                    lc3$posterior[,3] < 0.5 ~ 2,
                                  lc3$posterior[,3]  >= 0.5 &
                                    lc3$posterior[,1] < 0.5 &
                                    lc3$posterior[,2] < 0.5 ~ 3,
                                  TRUE ~ as.numeric(NA)))
data6$class <- as.factor(data6$class)
```

To further describe the classes in a broader context, graphs showing the distribution of type of intended teaching degree as well as gender per class are displayed below.

```{r}
data7 <- data6
data7$tg24202_g1 <- as.factor(data7$tg24202_g1)
data7$t700001 <- as.factor(data7$t700001)
levels(data7$tg24202_g1) <- c("primary education elementary school",
                              "lower secondary qualification",
                              "upper secondary qualification",
                              "vocational schools",
                              "special education",
                              "without differentiation")
data7$t700001 <- as.factor(data7$t700001)
levels(data7$t700001) <- c("male", "female")

data7 <- data7 %>%
  dplyr::filter(!is.na(tg24202_g1))  %>%
  dplyr::filter(!is.na(class)) %>%
  dplyr::rename(type_teaching_degree = tg24202_g1) %>%
  dplyr::rename(gender = t700001)

x <- ggplot(data7) + geom_bar(aes(x = class, 
                                  fill = type_teaching_degree),
           position = "dodge") + labs(x = "latent class") + theme_bw()

y <- ggplot(data7) + geom_bar(aes(x = class, 
                                  fill = gender),
           position = "dodge") + labs(x = "latent class") + theme_bw()

plot <- ggarrange(x, y, ncol = 1, nrow = 2)

plot
```

## Questions

-   What do you think about the handling of the variables regarding personality and motivation for choosing teacher education?
-   How would you rate the model selection?
-   Is the graphical representation of the final model via the mean value of each response understandable, given the presence of formal categories?
-   Do you know if Individual class assignment by modal posterior probability is (still) acceptable and a common practice?
-   General considerations and thoughts are of course very welcome.

## References

::: {#refs}
:::
